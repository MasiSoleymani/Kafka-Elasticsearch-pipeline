{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "869ee649-6760-4c68-abd5-fa919bd175ce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: elasticsearch 8.14.0\n",
      "Uninstalling elasticsearch-8.14.0:\n",
      "  Successfully uninstalled elasticsearch-8.14.0\n",
      "Collecting elasticsearch==8.14.0\n",
      "  Using cached elasticsearch-8.14.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.13 in ./.venv/lib/python3.12/site-packages (from elasticsearch==8.14.0) (8.17.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in ./.venv/lib/python3.12/site-packages (from elastic-transport<9,>=8.13->elasticsearch==8.14.0) (2.5.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from elastic-transport<9,>=8.13->elasticsearch==8.14.0) (2025.8.3)\n",
      "Using cached elasticsearch-8.14.0-py3-none-any.whl (480 kB)\n",
      "Installing collected packages: elasticsearch\n",
      "Successfully installed elasticsearch-8.14.0\n"
     ]
    }
   ],
   "source": [
    "!python -m pip uninstall -y elasticsearch\n",
    "!python -m pip install \"elasticsearch==8.14.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74c42d61-f066-4469-a7ca-0ce47f9557fb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.venv/lib/python3.12/site-packages (25.2)\n",
      "Requirement already satisfied: confluent-kafka in ./.venv/lib/python3.12/site-packages (2.11.1)\n",
      "Requirement already satisfied: ipykernel in ./.venv/lib/python3.12/site-packages (6.30.1)\n",
      "Requirement already satisfied: appnope>=0.1.2 in ./.venv/lib/python3.12/site-packages (from ipykernel) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./.venv/lib/python3.12/site-packages (from ipykernel) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.12/site-packages (from ipykernel) (1.8.16)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./.venv/lib/python3.12/site-packages (from ipykernel) (9.5.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in ./.venv/lib/python3.12/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.12/site-packages (from ipykernel) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./.venv/lib/python3.12/site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in ./.venv/lib/python3.12/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging>=22 in ./.venv/lib/python3.12/site-packages (from ipykernel) (25.0)\n",
      "Requirement already satisfied: psutil>=5.7 in ./.venv/lib/python3.12/site-packages (from ipykernel) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=25 in ./.venv/lib/python3.12/site-packages (from ipykernel) (27.0.2)\n",
      "Requirement already satisfied: tornado>=6.2 in ./.venv/lib/python3.12/site-packages (from ipykernel) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./.venv/lib/python3.12/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (2.19.2)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from jupyter-client>=8.0.0->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.4.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install confluent-kafka ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "376579c8-8eb9-4231-9795-34955e3f6e62",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN\u001b[0m[0000] /Users/ss/realtime-store/docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion \n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 3/3\n",
      " \u001b[32m✔\u001b[0m Container realtime-store-kafka-1  \u001b[32mRunning\u001b[0m                               \u001b[34m0.0s \u001b[0m\n",
      " \u001b[32m✔\u001b[0m Container es                      \u001b[32mRunning\u001b[0m                               \u001b[34m0.0s \u001b[0m\n",
      " \u001b[32m✔\u001b[0m Container kibana                  \u001b[32mRunning\u001b[0m                               \u001b[34m0.0s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 3/3\u001b[0m\n",
      " \u001b[32m✔\u001b[0m Container realtime-store-kafka-1  \u001b[32mRunning\u001b[0m                               \u001b[34m0.0s \u001b[0m\n",
      " \u001b[32m✔\u001b[0m Container es                      \u001b[32mRunning\u001b[0m                               \u001b[34m0.0s \u001b[0m\n",
      " \u001b[32m✔\u001b[0m Container kibana                  \u001b[32mRunning\u001b[0m                               \u001b[34m0.0s \u001b[0m\n",
      "\u001b[?25h{.Names}   {.Status}   {.Ports}\n",
      "{.Names}   {.Status}   {.Ports}\n",
      "{.Names}   {.Status}   {.Ports}\n",
      "{.Names}   {.Status}   {.Ports}\n"
     ]
    }
   ],
   "source": [
    "!docker compose up -d\n",
    "\n",
    "!docker ps --format \"table {{.Names}}\\t{{.Status}}\\t{{.Ports}}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cf5a66a-b27e-4754-a4a8-e4692916a27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Brokers: dict_keys([1])\n",
      "Topics: ['market_ticks', 'trade_orders', '__consumer_offsets']\n"
     ]
    }
   ],
   "source": [
    "from confluent_kafka.admin import AdminClient\n",
    "\n",
    "admin = AdminClient({\"bootstrap.servers\": \"localhost:9092\"})\n",
    "md = admin.list_topics(timeout=5)\n",
    "print(\"Connected. Brokers:\", md.brokers.keys())\n",
    "print(\"Topics:\", list(md.topics.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1af24bae-d0ec-49a4-84cc-3886600900a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to create topic 'trade_orders': KafkaError{code=TOPIC_ALREADY_EXISTS,val=36,str=\"Topic 'trade_orders' already exists.\"}\n",
      "Failed to create topic 'market_ticks': KafkaError{code=TOPIC_ALREADY_EXISTS,val=36,str=\"Topic 'market_ticks' already exists.\"}\n"
     ]
    }
   ],
   "source": [
    "from confluent_kafka.admin import NewTopic\n",
    "\n",
    "topics = [\n",
    "    NewTopic(\"trade_orders\", num_partitions=1, replication_factor=1),\n",
    "    NewTopic(\"market_ticks\", num_partitions=1, replication_factor=1),\n",
    "]\n",
    "\n",
    "fs = admin.create_topics(topics)\n",
    "\n",
    "for t, f in fs.items():\n",
    "    try:\n",
    "        f.result()  # The result itself is None\n",
    "        print(f\"Topic '{t}' created successfully\")\n",
    "    except Exception as e:\n",
    "        if \"Topic already exists\" in str(e):\n",
    "            print(f\"Topic '{t}' already exists (reusing it)\")\n",
    "        else:\n",
    "            print(f\"Failed to create topic '{t}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adae46de-518b-4799-a1d8-6241e8adee3e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent 50/400\n",
      "sent 100/400\n",
      "sent 150/400\n",
      "sent 200/400\n",
      "sent 250/400\n",
      "sent 300/400\n",
      "sent 350/400\n",
      "sent 400/400\n",
      "burst done\n"
     ]
    }
   ],
   "source": [
    "from confluent_kafka import Producer\n",
    "import json, random, time, uuid\n",
    "\n",
    "producer = Producer({\n",
    "    \"bootstrap.servers\": \"localhost:9092\",\n",
    "    \"enable.idempotence\": False,\n",
    "    \"acks\": \"all\",\n",
    "    \"linger.ms\": 5,\n",
    "    \"batch.size\": 32768\n",
    "})\n",
    "\n",
    "SYMBOLS = [\"AAPL\", \"MSFT\", \"TSLA\", \"NVDA\", \"BAC\", \"RY\", \"TD\", \"BNS\"]\n",
    "SIDES   = [\"BUY\", \"SELL\"]\n",
    "TYPES   = [\"NEW\", \"CANCEL\", \"EXECUTE\"]\n",
    "\n",
    "def make_order():\n",
    "    \"\"\"Build one fake trade/order event.\"\"\"\n",
    "    return {\n",
    "        \"event_type\": random.choices(TYPES, weights=[70, 10, 20])[0],\n",
    "        \"order_id\": str(uuid.uuid4()),\n",
    "        \"symbol\": random.choice(SYMBOLS),\n",
    "        \"side\":   random.choice(SIDES),\n",
    "        \"price\":  round(random.uniform(10, 500), 2),\n",
    "        \"qty\":    random.choice([10, 25, 50, 100, 200]),\n",
    "        \"ts\":     time.time(),\n",
    "    }\n",
    "\n",
    "TOPIC = \"trade_orders\"\n",
    "N = 400 \n",
    "\n",
    "for i in range(N):\n",
    "    evt = make_order()\n",
    "    producer.produce(\n",
    "        TOPIC,\n",
    "        key=evt[\"order_id\"].encode(),\n",
    "        value=json.dumps(evt).encode()\n",
    "    )\n",
    "    producer.poll(0)         \n",
    "    if (i + 1) % 50 == 0:\n",
    "        print(f\"sent {i+1}/{N}\")\n",
    "    time.sleep(0.01)         \n",
    "\n",
    "producer.flush(10)\n",
    "print(\"burst done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78632f45-cc6f-4ce9-b842-fe6471bb1127",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro-test: producing one message...\n",
      "delivered to trade_orders[0] @ offset 2898\n",
      "micro-test done\n"
     ]
    }
   ],
   "source": [
    "from confluent_kafka import Producer\n",
    "\n",
    "print(\"micro-test: producing one message...\")\n",
    "p = Producer({\"bootstrap.servers\": \"localhost:9092\", \"enable.idempotence\": False})\n",
    "\n",
    "def cb(err, msg):\n",
    "    if err:\n",
    "        print(\"delivery error:\", err)\n",
    "    else:\n",
    "        print(f\"delivered to {msg.topic()}[{msg.partition()}] @ offset {msg.offset()}\")\n",
    "\n",
    "p.produce(\"trade_orders\", key=b\"TEST\", value=b'{\"ping\":1}', on_delivery=cb)\n",
    "p.flush(10)   # wait up to 10s for the delivery report\n",
    "print(\"micro-test done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2936a4b8-d288-4c4a-9903-d66eaa61a0a9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade-orders 400 {\"error\":{\"root_cause\":[{\"type\":\"resource_already_exists_exception\",\"reason\":\"index [trade-orders/kQQzG6JyQ0CuW58kfsbD2Q] already exists\",\"index_uuid\":\"kQQzG6JyQ0CuW58kfsbD2Q\",\"index\":\"trade-orders\"}]\n",
      "market-ticks 400 {\"error\":{\"root_cause\":[{\"type\":\"resource_already_exists_exception\",\"reason\":\"index [market-ticks/QlLhxrubQoug0RyGiA8fgA] already exists\",\"index_uuid\":\"QlLhxrubQoug0RyGiA8fgA\",\"index\":\"market-ticks\"}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "trade_mappings = {\n",
    "  \"properties\": {\n",
    "    \"@timestamp\": {\"type\": \"date\"},\n",
    "    \"event_type\": {\"type\": \"keyword\"},\n",
    "    \"order_id\":   {\"type\": \"keyword\"},\n",
    "    \"symbol\":     {\"type\": \"keyword\"},\n",
    "    \"side\":       {\"type\": \"keyword\"},\n",
    "    \"price\":      {\"type\": \"double\"},\n",
    "    \"qty\":        {\"type\": \"integer\"}\n",
    "  }\n",
    "}\n",
    "\n",
    "tick_mappings = {\n",
    "  \"properties\": {\n",
    "    \"@timestamp\": {\"type\": \"date\"},\n",
    "    \"symbol\":     {\"type\": \"keyword\"},\n",
    "    \"last\":       {\"type\": \"double\"},\n",
    "    \"bid\":        {\"type\": \"double\"},\n",
    "    \"ask\":        {\"type\": \"double\"},\n",
    "    \"vol\":        {\"type\": \"integer\"}\n",
    "  }\n",
    "}\n",
    "\n",
    "def create_index_http(name, mappings):\n",
    "    r = requests.put(f\"http://localhost:9200/{name}\", json={\"mappings\": mappings}, timeout=10)\n",
    "    print(name, r.status_code, r.text[:200])\n",
    "\n",
    "create_index_http(\"trade-orders\", trade_mappings)\n",
    "create_index_http(\"market-ticks\", tick_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2f42ccb-f9b4-4659-99bd-b78ffcab0203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "es = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6161835c-d9a5-4893-ba90-4b32ab79f946",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subscribed to: ['trade_orders', 'market_ticks']\n",
      "Consuming... press stop/interrupt to end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/08/0t4f35796gzbwn37cdvpbs_m0000gn/T/ipykernel_11656/432300568.py:26: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  src[\"@timestamp\"] = datetime.datetime.utcfromtimestamp(src[\"ts\"]).isoformat(timespec=\"milliseconds\") + \"Z\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Flushed 5 docs -> ok=5\n",
      "Stopping consumer...\n",
      "Consumer closed\n"
     ]
    }
   ],
   "source": [
    "from confluent_kafka import Consumer, KafkaException\n",
    "from elasticsearch import helpers\n",
    "import json, datetime, requests\n",
    "\n",
    "ES_HOST = \"http://localhost:9200\"\n",
    "\n",
    "consumer = Consumer({\n",
    "    \"bootstrap.servers\": \"localhost:9092\",\n",
    "    \"group.id\": \"py-es-consumer\",\n",
    "    \"auto.offset.reset\": \"earliest\",\n",
    "    \"enable.auto.commit\": False\n",
    "})\n",
    "\n",
    "topics = [\"trade_orders\", \"market_ticks\"]\n",
    "consumer.subscribe(topics)\n",
    "print(f\"Subscribed to: {topics}\")\n",
    "\n",
    "BATCH = 5\n",
    "buf = []\n",
    "\n",
    "def to_es_action(msg):\n",
    "    topic = msg.topic()\n",
    "    src = json.loads(msg.value())\n",
    "\n",
    "    if \"ts\" in src:\n",
    "        src[\"@timestamp\"] = datetime.datetime.utcfromtimestamp(src[\"ts\"]).isoformat(timespec=\"milliseconds\") + \"Z\"\n",
    "\n",
    "    index = \"trade-orders\" if topic == \"trade_orders\" else \"market-ticks\"\n",
    "    doc_id = f\"{topic}-{msg.partition()}-{msg.offset()}\"\n",
    "\n",
    "    return {\"_index\": index, \"_id\": doc_id, \"_source\": src}\n",
    "\n",
    "try:\n",
    "    print(\"Consuming... press stop/interrupt to end\")\n",
    "    while True:\n",
    "        m = consumer.poll(0.5)\n",
    "        if m is None:\n",
    "            continue\n",
    "        if m.error():\n",
    "            raise KafkaException(m.error())\n",
    "\n",
    "        buf.append(to_es_action(m))\n",
    "\n",
    "        if len(buf) >= BATCH:\n",
    "            ok, _ = helpers.bulk(es, buf)   # buf contains {\"_index\",\"_id\",\"_source\"}\n",
    "            print(f\"Flushed {len(buf)} docs -> ok={ok}\")\n",
    "            buf.clear()\n",
    "            consumer.commit()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopping consumer...\")\n",
    "\n",
    "finally:\n",
    "    consumer.close()\n",
    "    print(\"Consumer closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9649383c-9796-4a62-944c-2ae1fa7cf067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produced 20 events to 'trade_orders'\n"
     ]
    }
   ],
   "source": [
    "from confluent_kafka import Producer\n",
    "import json, time, uuid, random\n",
    "\n",
    "p = Producer({\"bootstrap.servers\": \"localhost:9092\"})\n",
    "\n",
    "def make_event(i):\n",
    "    return {\n",
    "        \"event_type\": \"NEW\",\n",
    "        \"order_id\": str(uuid.uuid4()),\n",
    "        \"symbol\": random.choice([\"AAPL\",\"MSFT\",\"NVDA\",\"TSLA\"]),\n",
    "        \"side\": random.choice([\"BUY\",\"SELL\"]),\n",
    "        \"price\": round(100 + random.random()*50, 2),\n",
    "        \"qty\": random.choice([10,25,50,100]),\n",
    "        \"ts\": time.time(),  # seconds since epoch\n",
    "    }\n",
    "\n",
    "for i in range(20):\n",
    "    evt = make_event(i)\n",
    "    p.produce(\"trade_orders\", key=str(i).encode(), value=json.dumps(evt).encode())\n",
    "\n",
    "p.flush(10)\n",
    "print(\"Produced 20 events to 'trade_orders'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adad739d-6b66-4bf1-aa4d-d2c969e059ff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade-orders count: {'count': 2495, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n",
      "market-ticks count: {'count': 0, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n",
      "{\n",
      "  \"took\": 15,\n",
      "  \"timed_out\": false,\n",
      "  \"_shards\": {\n",
      "    \"total\": 1,\n",
      "    \"successful\": 1,\n",
      "    \"skipped\": 0,\n",
      "    \"failed\": 0\n",
      "  },\n",
      "  \"hits\": {\n",
      "    \"total\": {\n",
      "      \"value\": 2495,\n",
      "      \"relation\": \"eq\"\n",
      "    },\n",
      "    \"max_score\": null,\n",
      "    \"hits\": [\n",
      "      {\n",
      "        \"_index\": \"trade-orders\",\n",
      "        \"_id\": \"trade_orders-0-2896\",\n",
      "        \"_score\": null,\n",
      "        \"_source\": {\n",
      "          \"event_type\": \"NEW\",\n",
      "          \"order_id\": \"865045fb-87c5-40b7-a0a7-7aa5788cfce8\",\n",
      "          \"symbol\": \"TSLA\",\n",
      "          \"side\": \"SELL\",\n",
      "          \"price\": 477.2,\n",
      "          \"qty\": 50,\n",
      "          \"ts\": 1758161268.1144059,\n",
      "          \"@timestamp\": \"2025-09-18T02:07:48.114Z\"\n",
      "        },\n",
      "        \"sort\": [\n",
      "          1758161268114\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "print(\"trade-orders count:\", requests.get(\"http://localhost:9200/trade-orders/_count\").json())\n",
    "print(\"market-ticks count:\", requests.get(\"http://localhost:9200/market-ticks/_count\").json())\n",
    "\n",
    "resp = requests.get(\"http://localhost:9200/trade-orders/_search\", params={\"size\": 1, \"sort\": \"@timestamp:desc\"})\n",
    "print(json.dumps(resp.json(), indent=2)[:1200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf09bcd4-49db-4aeb-9109-002de6dd6b90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (realtime-store)",
   "language": "python",
   "name": "realtime-store"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
